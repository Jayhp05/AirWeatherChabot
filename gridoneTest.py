import streamlit as st
import requests
import xml.etree.ElementTree as ET
from langchain_community.vectorstores import FAISS
from langchain.schema import Document
from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings
from langchain_community.chat_models import ChatOllama
from langchain.prompts import ChatPromptTemplate
from langchain.schema.runnable import RunnableMap

# API í‚¤
key = 'KPXkp9A5jCelRkUuOvT3EfPP0nOgvtQUiRySPCUmIPHtzYSE6G9/vLanfYwDPYz6JfL2K6HaXTIMOLyW1c3zwA=='

url_request = 'http://apis.data.go.kr/B551177/StatusOfPassengerWorldWeatherInfo/getPassengerArrivalsWorldWeather'

# API ìš”ì²­ í•¨ìˆ˜
def get_passenger_arrivals():
    url = url_request
    params = {
        'serviceKey': key, 
        'numOfRows': '10', 
        'pageNo': '1', 
        'from_time': '0000', 
        'to_time': '2400', 
        'airport': '', 
        'flight_id': '', 
        'airline': '', 
        'lang': 'K', 
        'type': 'xml'
    }
    response = requests.get(url, params=params)
    content = response.content.decode('utf-8')
    data = ET.fromstring(content)
    return data

def get_passenger_departures():
    url = url_request
    params = {
        'serviceKey': key, 
        'numOfRows': '10', 
        'pageNo': '1', 
        'from_time': '0000', 
        'to_time': '2400', 
        'airport': '', 
        'flight_id': '', 
        'airline': '', 
        'lang': 'K', 
        'type': 'xml'
    }
    response = requests.get(url, params=params)
    content = response.content.decode('utf-8')
    data = ET.fromstring(content)
    return data

def parse_weather_quality_data(data):
    items = data.find('.//items')
    weather_quality_info = []
    
    if items is not None:
        for item in items.findall('item'):
            flight_info = {
                'í•­ê³µì‚¬': item.find('airline').text if item.find('airline') is not None else None,
                'í¸ëª…': item.find('flightId').text if item.find('flightId') is not None else None,
                'ì˜ˆì •ì‹œê°„': item.find('scheduleDateTime').text if item.find('scheduleDateTime') is not None else None,
                'ë³€ê²½ì‹œê°„': item.find('estimatedDateTime').text if item.find('estimatedDateTime') is not None else None,
                'ì¶œë°œê³µí•­': item.find('airport').text if item.find('airport') is not None else None,
                'í˜„í™©': item.find('remark').text if item.find('remark') is not None else None,
                'ê³µí•­ì½”ë“œ': item.find('airportCode').text if item.find('airportCode') is not None else None,
                'ë‚ ì”¨í‘œì¶œ ìš”ì¼': item.find('yoil').text if item.find('yoil') is not None else None,
                'ìŠµë„': item.find('himidity').text if item.find('himidity') is not None else None,
                'í’ì†': item.find('wind').text if item.find('wind') is not None else None,
                'ê´€ì¸¡ ê¸°ì˜¨': item.find('temp').text if item.find('temp') is not None else None,
                'ì²´ê° ê¸°ì˜¨': item.find('senstemp').text if item.find('senstemp') is not None else None,
            }
            weather_quality_info.append(flight_info)
    else:
        st.write("ì •ë³´ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    
    return weather_quality_info

# Streamlit UI ì„¤ì •
st.title("ê³µí•­ ë‚ ì”¨ ì±—ë´‡")
st.write("ì¶œë°œì§€ ë‚ ì”¨ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ë¬¼ì–´ë³´ì„¸ìš”!")
st.write("ğŸ™‚ ì¸ì²œêµ­ì œê³µí•­ê´€ë ¨ ë¹„í–‰ê¸° ì‹œê°„ì •ë³´ë„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.")

# ì‚¬ìš©ì ì…ë ¥
user_input = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:", "")

if user_input:
    # ë„ì°© ë° ì¶œë°œ ì •ë³´ í˜¸ì¶œ
    arrivals_data = get_passenger_arrivals()
    departures_data = get_passenger_departures()
    
    # ë‚ ì”¨ ì •ë³´ íŒŒì‹±
    arrivals_info = parse_weather_quality_data(arrivals_data)
    departures_info = parse_weather_quality_data(departures_data)

    # ë‚ ì”¨ ì •ë³´ ë¬¸ì„œ ìƒì„±
    documents = [Document(page_content=", ".join([f"{key}: {str(info[key])}" for key in ['í•­ê³µì‚¬', 'í¸ëª…', 'ì˜ˆì •ì‹œê°„', 'ë³€ê²½ì‹œê°„', 'ì¶œë°œê³µí•­','ìŠµë„', 'í’ì†', 'ê´€ì¸¡ ê¸°ì˜¨', 'ì²´ê° ê¸°ì˜¨']])) for info in arrivals_info]
    documents += [Document(page_content=", ".join([f"{key}: {str(info[key])}" for key in ['í•­ê³µì‚¬', 'í¸ëª…', 'ì˜ˆì •ì‹œê°„', 'ë³€ê²½ì‹œê°„', 'ì¶œë°œê³µí•­', 'ìŠµë„', 'í’ì†', 'ê´€ì¸¡ ê¸°ì˜¨', 'ì²´ê° ê¸°ì˜¨']])) for info in departures_info]

    # ì„ë² ë”© í•¨ìˆ˜ ì„¤ì •
    embedding_function = SentenceTransformerEmbeddings(model_name="jhgan/ko-sroberta-multitask")
    db = FAISS.from_documents(documents, embedding_function)
    
    # ë¬¸ì„œ ê²€ìƒ‰
    retriever = db.as_retriever(search_type="similarity", search_kwargs={'k': 5, 'fetch_k': 100})
    
    # ì±—ë´‡ ì‘ë‹µ ìƒì„±
    template = """
    ë°˜ë“œì‹œ ì‚¬ìš©ìì—ê²Œ í•œê¸€ë¡œ ì•Œë ¤ì£¼ì„¸ìš”.
    ë„ˆëŠ” ì•„ì£¼ ì¹œì ˆí•œ ê³µí•­ ì§ì›ì´ì•¼.
    ì‚¬ìš©ìì—ê²Œ ì¹œì ˆí•œ ë§íˆ¬ë¡œ ì˜ ì„¤ëª…í•´ì¤˜.
    Answer the question as based only on the following context:
    {context}
     
    Question: {question}
    """
    
    prompt = ChatPromptTemplate.from_template(template)
    
    llm = ChatOllama(model="gemma2:9b", temperature=0, base_url="http://127.0.0.1:11434/")
    
    chain = RunnableMap({
        "context": lambda x: retriever.get_relevant_documents(x['question']),
        "question": lambda x: x['question']
    }) | prompt | llm
    
    response = chain.invoke({'question': user_input}).content
    
    st.markdown(response)